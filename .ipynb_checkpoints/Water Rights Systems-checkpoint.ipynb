{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts scrap data from the Utah Water Rights website, saves the data to text files, then parses the text files into a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "from urllib2 import urlopen\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as tick\n",
    "import scipy.stats as sp\n",
    "import statsmodels.api as sm\n",
    "from pandas.stats.api import ols\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from pylab import rcParams\n",
    "import platform\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import urllib\n",
    "import HTMLParser\n",
    "from cStringIO import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose output routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route = 'C:/PROJECTS/WR_DATA/'\n",
    "wellpath = 'M:/PROJECTS/WR_DATA/RawWellogs/'\n",
    "syspath = 'M:/PROJECTS/WR_DATA/RawSystems/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser and Scraper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    # opens webpage for use in BeautifulSoup    \n",
    "    html = urlopen(url).read()\n",
    "    return BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Log Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapes well Logs from Water Rights website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Water Rights win number to begin search\n",
    "winbegin = 34000\n",
    "space = 1000\n",
    "winend = winbegin + space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while winbegin < 60000:\n",
    "       \n",
    "    # opens waterrights webpage by win   \n",
    "    for i in range(winbegin,winend):\n",
    "        try:\n",
    "            win = str(i)\n",
    "            soup = make_soup('http://waterrights.utah.gov/cgi-bin/docview.exe?Folder=welllog'+str(i))\n",
    "            souplist = soup.find('a', href=re.compile('^http://waterrights.utah.gov/docSys/v907/.*'))['href']\n",
    "            soupsite = make_soup(souplist)\n",
    "            souptext = soupsite.get_text()\n",
    "            g = path + 'log' + str(win).zfill(5) + '.txt'    \n",
    "            b = open(g, 'w')\n",
    "            b.write(souptext.encode('utf-8'))\n",
    "            b.close()\n",
    "        except TypeError:        \n",
    "            pass\n",
    "    \n",
    "    winbegin = winend\n",
    "    winend = winbegin + space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water System Use Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: http://www.waterrights.utah.gov/wateruse/WaterUseList.asp<br/>\n",
    "Example Pages of Input:<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Indview&SYSTEM_ID=11247<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Mgtview&SYSTEM_ID=11228<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def systemscraper(winbegin,winfinish,space,prefix,path):\n",
    "    '''\n",
    "    Systematically progresses though integer id numbers at the end of Water Rights URL to find system pages, \n",
    "    then saves those pages to text files.\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    winbegin = integer value to start search\n",
    "    space = number of integers to search at a time\n",
    "    winfinish = integer value to end search\n",
    "    prefix = subset of systems to search (Modinfo= value in URL); can be Pws, Ind, or Mgt\n",
    "    path = place to store resulting text files\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    text files in path labeled with corresponding integer values\n",
    "    '''\n",
    "    winend = winbegin + space\n",
    "\n",
    "    while winbegin < winfinish:\n",
    "\n",
    "        systemnm = []\n",
    "\n",
    "        # opens waterrights webpage by win   \n",
    "        for i in range(winbegin,winend):\n",
    "            try:\n",
    "                htmlplace = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=' + str(prefix) + 'view&SYSTEM_ID='+str(i)\n",
    "                soup = make_soup(htmlplace).get_text()\n",
    "                if \"ERROR: Use UNITS undefined\" in soup or len(soup) < 1000:\n",
    "                    pass\n",
    "                else:\n",
    "                    systemnm.append(str(i))\n",
    "                    g = path + str(prefix) + str(i).zfill(6) + '.txt'\n",
    "                    b = open(g, 'w')\n",
    "                    b.write(soup.encode('utf-8').strip())   \n",
    "                    b.close()\n",
    "            except TypeError:        \n",
    "                pass\n",
    "\n",
    "        winbegin = winend\n",
    "        winend = winbegin + space\n",
    "    print(\"Scanned %s to %s\"%(prefix,winfinish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned Pws to 3000\n",
      "Scanned Pws to 13000\n",
      "Scanned Ind to 3000\n",
      "Scanned Ind to 13000\n",
      "Scanned Mgt to 3000\n",
      "Scanned Mgt to 13000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "systems = ['Pws','Ind','Mgt']\n",
    "\n",
    "for i in systems:\n",
    "    systemscraper(0,3000,1000,i,syspath)\n",
    "    systemscraper(10000,13000,1000,i,syspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches through text captures of Water Rights html well files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = wellpath + '*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raises(exception_types, func, *args, **kw):\n",
    "    try:\n",
    "        func(*args, **kw)\n",
    "    except exception_types:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tparser(blurb):\n",
    "    '''\n",
    "    parses a snippet of text from gettext by removing and replaces extra spaces and return characters\n",
    "    '''\n",
    "    blurb = re.sub('\\r\\n      +', '\\n',str(blurb))\n",
    "    blurb = re.sub('\\r\\n +','\\r\\n',blurb)\n",
    "    blurb = re.sub(',',';',blurb)\n",
    "    blurb = re.sub(' +',',',blurb)\n",
    "    blurb = re.sub('\\r\\n','\\n',blurb)\n",
    "    blurb = re.sub('\\n\\n','\\n',blurb)\n",
    "    return blurb\n",
    "\n",
    "def gettext(strttext,endtext,snip):\n",
    "    '''\n",
    "    selects a subset of text by searching the text for a beginning string and an ending string\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    strttext = string to find that begins text subset\n",
    "    endtext = string to find that ends the text subset\n",
    "    snip = text to subset\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    b = subset of text; returns np.nan if no strttext is found\n",
    "    '''\n",
    "    \n",
    "    b = snip[snip.find(strttext)+len(strttext):snip.find(endtext,snip.find(strttext))].strip()\n",
    "    if snip.find(strttext) == -1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Level Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "wl = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' WATER LEVEL DATA:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:21] + ',' + rv[j][30:38].replace(',',';').strip(' ') + ',' + rv[j][38:].strip(' ')\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                else:\n",
    "                    pass\n",
    "            wl.append('\\n'.join(rr))\n",
    "\n",
    "levs = '\\n'.join(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels = pd.read_csv(StringIO(levs),names=['WIN','Date','Level','Method'],parse_dates=['Date'])\n",
    "waterlevels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "br = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' BOREHOLE INFORMATION:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:17] + ',' + rv[j][17:23] + ',' + rv[j][23:29]+ ',' + rv[j][29:58]+ ',' + rv[j][58:]\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                    #print(rv[j])\n",
    "                else:\n",
    "                    pass\n",
    "            br.append('\\n'.join(rr))\n",
    "   \n",
    "bore = '\\n'.join(br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "borehole = pd.read_csv(StringIO(bore),names=['WIN','From_ft','To_ft','Diameter','Method','Fluid'])\n",
    "borehole.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Activity Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "\n",
    "rr = []\n",
    "for f in glob.glob(filepath):\n",
    "    \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    wellcon = gettext(' DRILLER ACTIVITIES:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            \n",
    "            act1 = str(gettext('ACTIVITY # 1 ','\\r\\n\\r\\n',wellcon))\n",
    "            actnm1 = str(gettext('ACTIVITY # 1 ','\\r\\n',wellcon)).strip(' ')\n",
    "            drllr1 = str(gettext('DRILLER: ','LICENSE #:',act1)).replace(',',' ').strip(' ')\n",
    "            lic1 =  str(gettext('LICENSE #:','\\r\\n',act1)).strip(' ')\n",
    "            strt1 = str(gettext('START DATE: ','COMPLETION DATE: ',act1)).strip(' ')\n",
    "            comp1 = str(gettext('COMPLETION DATE: ','\\r\\n',act1)).strip(' ')\n",
    "            rr.append(win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1)\n",
    "            #print win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1\n",
    "            if 'ACTIVITY # 2' in wellcon: \n",
    "                act2 = str(gettext('ACTIVITY # 2 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm2 = str(gettext('ACTIVITY # 2 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr2 = str(gettext('DRILLER: ','LICENSE #:',act2)).replace(',',' ').strip(' ')\n",
    "                lic2 =  str(gettext('LICENSE #:','\\r\\n',act2)).strip(' ')\n",
    "                strt2 = str(gettext('START DATE: ','COMPLETION DATE: ',act2)).strip(' ')\n",
    "                comp2 = str(gettext('COMPLETION DATE: ','\\r\\n',act2)).strip(' ')\n",
    "                rr.append(win+','+actnm2+','+drllr2+','+lic2+','+strt2+','+comp2)\n",
    "    \n",
    "            if 'ACTIVITY # 3' in wellcon:\n",
    "                act3 = str(gettext('ACTIVITY # 3 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm3 = str(gettext('ACTIVITY # 3 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr3 = str(gettext('DRILLER: ','LICENSE #:',act3)).replace(',',' ').strip(' ')\n",
    "                lic3 =  str(gettext('LICENSE #:','\\r\\n',act3)).strip(' ')\n",
    "                strt3 = str(gettext('START DATE: ','COMPLETION DATE: ',act3)).strip(' ')\n",
    "                comp3 = str(gettext('COMPLETION DATE: ','\\r\\n',act3)).strip(' ')\n",
    "                rr.append(win+','+actnm3+','+drllr3+','+lic3+','+strt3+','+comp3)\n",
    "drill = '\\n'.join(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driller = pd.read_csv(StringIO(drill),names=['WIN','activity','driller','license','start','completion'],index_col=False)#,parse_dates=['start','completion'])\n",
    "driller.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lithology Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "lit = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    litho = gettext(' LITHOLOGY:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if litho is not np.nan:\n",
    "        if len(litho) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = litho.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if j == len(rv):\n",
    "                    rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                else:\n",
    "                    if len(rv[j][0:8].strip(' ')) < 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                        try:\n",
    "                            if len(rv[j+1][0:8].strip(' ')) < 1:\n",
    "                                if len(rv[j+1].replace('  ',' ').strip(' '))<350:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')\n",
    "                                else:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')[0:350]\n",
    "                        except(IndexError):\n",
    "                            pass\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            lit.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "lith = '\\n'.join(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog = pd.read_csv(StringIO(lith),names=['WIN','From_ft','To_ft','Material','Color','Rock Type','Comment'])\n",
    "lithlog.drop_duplicates(inplace=True)\n",
    "lithlog.From_ft = pd.to_numeric(lithlog.From_ft, errors='coerce')\n",
    "lithlog.To_ft = pd.to_numeric(lithlog.To_ft, errors='coerce')\n",
    "lithlog.dropna(subset=['From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lithsort(lith, x):      \n",
    "    if str(lith).lower() in str(x).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lithsorth(lith, x):\n",
    "    if 'other' in str(x[0]).lower():\n",
    "        b = str(x[0]).lower() + ' ' + str(x[1]).upper()\n",
    "    else:\n",
    "        b = x[0]\n",
    "    if str(lith).lower() in str(b).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    \n",
    "lithlog['low_perm'] = lithlog['Material'].apply(lambda x: lithsort('LOW-PERMEABILITY', x),1)\n",
    "lithlog['high_perm'] = lithlog['Material'].apply(lambda x: lithsort('HIGH-PERMEABILITY', x),1)\n",
    "lithlog['clay'] = lithlog['Material'].apply(lambda x: lithsort('clay', x),1)\n",
    "lithlog['silt'] = lithlog['Material'].apply(lambda x: lithsort('silt', x),1)\n",
    "lithlog['sand'] = lithlog['Material'].apply(lambda x: lithsort('sand', x),1)\n",
    "lithlog['gravel'] = lithlog['Material'].apply(lambda x: lithsort('gravel', x),1)\n",
    "lithlog['cobbles'] = lithlog['Material'].apply(lambda x: lithsort('cobbles', x),1)\n",
    "lithlog['boulders'] = lithlog['Material'].apply(lambda x: lithsort('boulders', x),1)\n",
    "lithlog['hardpan'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('hardpan', x),1)\n",
    "lithlog['conglomerate'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('conglomerate', x),1)\n",
    "lithlog['bedrock'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('bedrock', x),1)\n",
    "lithlog['other'] = lithlog['Material'].apply(lambda x: lithsort('other', x),1)\n",
    "lithlog['water_bearing'] = lithlog['Material'].apply(lambda x: lithsort('water-bearing', x),1)\n",
    "\n",
    "\n",
    "def unitassign(x):\n",
    "    clay = x[0]\n",
    "    silt = x[1]\n",
    "    sand = x[2]\n",
    "    gravel = x[3]\n",
    "    cobbles = x[4]\n",
    "    boulders = x[5]\n",
    "    hardpan = x[6]\n",
    "    conglomerate = x[7]\n",
    "    bedrock = x[8]\n",
    "    other = x[9]\n",
    "    unitlist = [clay,silt,sand,gravel,cobbles,boulders, hardpan,conglomerate,bedrock,other]\n",
    "    unitindex = ['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']\n",
    "    unitsum = np.sum(unitlist)\n",
    "    j =str(\"\")\n",
    "    for i in range(len(unitlist)):\n",
    "        if unitlist[i] == 1:\n",
    "            if len(j)==0:\n",
    "                j = unitindex[i]\n",
    "            else:\n",
    "                j = j + \"-\" + unitindex[i]\n",
    "    return j    \n",
    "\n",
    "lithlog.units = lithlog[['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']].apply(lambda x: unitassign(x),1)\n",
    "\n",
    "consdict = {'other':'other', 'boulders':'gravel', 'gravel':'gravel', 'sand-gravel-cobbles':'sand-gravel',\n",
    "            'sand-gravel-cobbles-boulders':'sand-gravel', 'clay-boulders':'clay-gravel', \n",
    "            'clay-gravel-boulders':'clay-gravel', 'gravel-conglomerate':'conglomerate', 'cobbles':'gravel',\n",
    "            'gravel-cobbles':'gravel', 'gravel-boulders':'gravel', 'clay-gravel-cobbles-boulders':'clay-gravel', \n",
    "            'gravel-cobbles-boulders':'gravel', 'clay-cobbles-boulders':'clay-gravel', \n",
    "            'clay-cobbles':'clay-gravel','clay-sand-gravel-cobbles':'clay-gravel', \n",
    "            'clay-hardpan':'hardpan', 'cobbles-boulders':'gravel', 'clay-gravel-cobbles':'clay-gravel', \n",
    "            'clay-conglomerate':'conglomerate', 'clay-silt-sand-gravel-conglomerate':'conglomerate', \n",
    "            'sand-gravel-boulders':'sand-gravel','sand-boulders':'sand-gravel','clay-silt-gravel':'clay-gravel',\n",
    "           'clay-silt-sand':'clay-sand','clay-silt':'clay-sand','clay-sand-gravel':'clay-gravel',\n",
    "           'silt-sand':'sand','clay-silt-gravel-cobbles':'clay-gravel','silt-sand-gravel':'sand-gravel'}\n",
    "\n",
    "lithlog['unitssimp'] = lithlog.units.apply(lambda x:consdict.get(x,x),1)\n",
    "\n",
    "\n",
    "def otherassign(x):\n",
    "    if x[0] == 'other' or x[0]=='':\n",
    "        if str(x[1]).lower().find('soil') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('overburden') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return ''\n",
    "    elif x[0] == 'bedrock':\n",
    "        if str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return 'bedrock'\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "lithlog['unitssimp'] = lithlog[['unitssimp','Comment']].apply(lambda x:otherassign(x),1)\n",
    "\n",
    "unitnumber = {'soil':0, 'sand-gravel':1, 'clay':2, 'gravel':1, 'sand':4, 'clay-gravel':5,\n",
    "              'clay-sand':3, 'conglomerate':7, 'hardpan':2, 'bedrock':6, 'limestone':6,\n",
    "              'sand-gravel-other':1, 'clay-silt-sand-gravel':3, 'clay-silt-other':2,\n",
    "              'silt':2, 'clay-other':2, 'shale':2}\n",
    "lithlog['unitnumber'] = lithlog['unitssimp'].apply(lambda x: unitnumber.get(x,8),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "const = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "\n",
    "    rev = []\n",
    "\n",
    "    wellcon = gettext('CASING:','\\r\\n\\r\\n',text)\n",
    "\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Material                                    Gage                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:20].replace('+','-') + ',' + rv[j][20:24].strip(' ') + ',' + rv[j][24:45].replace(',',';').strip(' ') + ',' + rv[j][45:57].strip(' ') +','+rv[j][57:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            const.append('\\n'.join(rr))\n",
    "\n",
    "\n",
    "\n",
    "constList = '\\n'.join(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction = pd.read_csv(StringIO(constList),names=['WIN','From_ft','To_ft','Material','Gage_in','Diameter_in'])\n",
    "construction.drop_duplicates(inplace=True)\n",
    "construction.From_ft = pd.to_numeric(construction.From_ft,errors='coerce')\n",
    "construction.To_ft = pd.to_numeric(construction.To_ft,errors='coerce')\n",
    "construction.Diameter_in = pd.to_numeric(construction.Diameter_in,errors='coerce')\n",
    "construction.dropna(subset=['WIN','From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "srn = []\n",
    "for f in glob.glob(filepath):    \n",
    "    text = open(f).read()   \n",
    "\n",
    "    scrntxt = gettext('SCREENS/PERFORATIONS:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    if scrntxt is not np.nan:\n",
    "        if len(scrntxt) > 10:    \n",
    "\n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = scrntxt.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Type                                                Slot                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:18].replace('+','-') + ',' + rv[j][18:25].strip(' ') + ',' + rv[j][25:53].replace(',',';').strip(' ') + ',' + rv[j][53:69].strip(' ') +','+ rv[j][69:97].strip(' ').replace('  ',' ') +','+ rv[j][97:].replace(',',';').strip(' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            srn.append('\\n'.join(rr))\n",
    "            \n",
    "scrrn = '\\n'.join(srn)\n",
    "\n",
    "screendf = pd.read_csv(StringIO(scrrn),names=['WIN','From_ft','To_ft','Screen Type',\n",
    "                                    'Slot_Size_in','Scrn_Diam_in','Perfs'])\n",
    "screendf.drop_duplicates(inplace=True)\n",
    "\n",
    "screendf.From_ft = pd.to_numeric(screendf.From_ft,errors='coerce')\n",
    "screendf.To_ft = pd.to_numeric(screendf.To_ft,errors='coerce')\n",
    "\n",
    "scrnInt = screendf.groupby('WIN').agg({'From_ft':np.min, 'To_ft':np.min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrnInt.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pumping Test Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "pmp = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    welltest = gettext('WELL TESTS:','\\r\\n\\r\\n\\r\\n ',text)\n",
    "    #print wellcon\n",
    "    if welltest is not np.nan:\n",
    "        if len(welltest) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = welltest.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           DATE                    Test Method                                  Yield                                    Drawdown                        Time pump                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:22] + ',' + rv[j][22:41].replace(',',';').strip(' ') + ',' + rv[j][41:54].strip(' ') + ',' + rv[j][54:70].strip(' ') +','+rv[j][70:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            pmp.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "pump = '\\n'.join(pmp)\n",
    "\n",
    "pumpingtests = pd.read_csv(StringIO(pump), names=['WIN', 'Date', 'Method', 'Yield_cfs', \n",
    "                                                  'Drawdown_ft', 'Pump_Dur_hr'])#,parse_dates=['Date'])\n",
    "pumpingtests.drop_duplicates(inplace=True)\n",
    "pumpingtests['Yield_cfs'] = pd.to_numeric(pumpingtests.Yield_cfs, errors='coerce')\n",
    "pumpingtests['Drawdown_ft'] = pd.to_numeric(pumpingtests.Drawdown_ft, errors='coerce')\n",
    "pumpingtests['Pump_Dur_hr'] = pd.to_numeric(pumpingtests.Pump_Dur_hr, errors='coerce')\n",
    "pumpingtests.dropna(subset=['Yield_cfs','Drawdown_ft','Pump_Dur_hr'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT = pd.merge(pumpingtests, construction, on='WIN',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrans(x,S):\n",
    "    Q = float(x[0])*86400.0\n",
    "    d = float(x[1])\n",
    "    t = float(x[2])/24.0\n",
    "    if d == 0:\n",
    "        sc = Q/0.1\n",
    "    else:\n",
    "        sc = Q/d\n",
    "        \n",
    "    r = float(x[3])/24.0\n",
    "    if r == 0:\n",
    "        return np.nan\n",
    "\n",
    "    else:\n",
    "        T0 = 100.0\n",
    "        delt = 100.0\n",
    "        while abs(delt) > 0.01:\n",
    "            T = (sc/(4*np.pi))*(np.log((2.25*T0*t)/(r*r*S)))\n",
    "            delt = T - T0\n",
    "            T0 = T\n",
    "        return T\n",
    "             \n",
    "S = 0.0002\n",
    "\n",
    "pumpT['trans'] = pumpT[['Yield_cfs','Drawdown_ft','Pump_Dur_hr','Diameter_in']].apply(lambda x: getTrans(x,S),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT.drop(['From_ft','To_ft','Material','Gage_in'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans = pd.merge(pumpT, scrnInt, on='WIN', how='left')\n",
    "wellTrans.dropna(subset=['trans'],inplace=True)\n",
    "wellTrans = wellTrans[(wellTrans.Drawdown_ft > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System and Source Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathname = 'C:\\\\PROJECTS\\\\WR_DATA\\\\RawSystems\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob(pathname +'*.txt')\n",
    "\n",
    "sourcet, conn, use = {}, {}, {}\n",
    "\n",
    "indcode, systype, sysnum, link, sysname, city, county, syscat, huc, pwsid, deqcat, numberofsources = [],[],[],[],[],[],[],[],[],[],[],[]\n",
    "source, system, systemid, pls, sourcetype, sourceuse, win, wrnum, sourcecode,sourceid = [],[],[],[],[],[],[],[],[],[]\n",
    "system_id = []\n",
    "\n",
    "for f in range(len(files)): \n",
    "    text = open(files[f]).read()\n",
    "    systemname = gettext('System  Name:','Address:',text)\n",
    "    sid = gettext('Public Water System ID:','DEQ',text)\n",
    "    srcind = [m.start() for m in re.finditer('Source Summary', text)]\n",
    "    \n",
    "    prefix = os.path.split(files[f])[1][0:3]\n",
    "    html = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo='+ prefix +'view&SYSTEM_ID='\n",
    "    \n",
    "    sysnum.append(int(os.path.split(files[f])[1][3:9]))\n",
    "    linknum = int(os.path.split(files[f])[1][3:9])\n",
    "    systype.append(prefix)\n",
    "    link.append(html+str(linknum))\n",
    "    \n",
    "    systid = prefix+'-'+str(linknum).zfill(5)\n",
    "    \n",
    "    system_id.append(systid)\n",
    "    sysname.append(gettext('System  Name:','Address:',text))\n",
    "    city.append(gettext('City:','State:',text))\n",
    "    county.append(gettext('County:','Primary Use:',text))\n",
    "    syscat.append(gettext('Primary Use:','Standard',text))\n",
    "    huc.append(gettext('Hydro Unit Code:','Public',text))\n",
    "    pwsid.append(gettext('Public Water System ID:','DEQ',text))\n",
    "    deqcat.append(gettext('DEQ System Category:','\\n',text))\n",
    "    indcode.append(gettext('Standard Industrial Code:','Dual',text))\n",
    "    \n",
    "    numberofsources.append(len(srcind))\n",
    "    \n",
    "    for i in range(len(srcind)):\n",
    "\n",
    "        if i == len(srcind)-1:\n",
    "            subtext = text[srcind[i]:-1]\n",
    "        else:\n",
    "            subtext = text[srcind[i]:srcind[i+1]]\n",
    "            \n",
    "        source.append(gettext('Source Name:','\\n',subtext))\n",
    "        pls.append(gettext('PLS Location:','\\n',subtext))\n",
    "        sourcetype.append(gettext('Source Type:','\\n',subtext))\n",
    "        sourceuse.append(gettext('Primary Use:','\\n',subtext))\n",
    "        win.append(gettext('Well ID Number:','(C',subtext))\n",
    "        sourcecode.append(gettext('DEHN Source Code:','\\n',subtext))\n",
    "        wrnum.append(gettext('Water Right Numbers:','\\n',subtext))\n",
    "        system.append(systemname)\n",
    "        systemid.append(sid)\n",
    "        srcid = systid +'-'+str(i).zfill(2)\n",
    "        sourceid.append(srcid)\n",
    "        \n",
    "        table = gettext(' Source Record (ACFT)\\r\\n','\\r\\n \\r',subtext)\n",
    "        table = re.sub('Master +Meter','MasterMeter',str(table))\n",
    "        table = re.sub('Master +Met','MasterMeter',table)\n",
    "        table = re.sub('Individual +Meters','IndividualMeters',table)\n",
    "        table = re.sub('Measuring +Method','MeasuringMethod',table)\n",
    "        table = tparser(table) \n",
    "        rv = table.split('\\n')\n",
    "        b = []\n",
    "        for j in range(len(rv)):    \n",
    "            if rv[j].count(',') > 15:\n",
    "                rb = rv[j].split(',')\n",
    "                rb.insert(15,'\\n')\n",
    "                b.append(','.join(rb))\n",
    "            elif rv[j].count(',')==15:\n",
    "                b.append(rv[j])  \n",
    "            elif rv[j].count(',') < 15 and rv[j].count(',') > 4:\n",
    "                b.append(rv[j] + ','*(15-rv[j].count(',')))\n",
    "            else:\n",
    "                pass\n",
    "        rev = '\\n'.join(b)\n",
    "        try:\n",
    "            sourcet[srcid] = pd.read_csv(StringIO(rev))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    usetable = gettext(' Annual Use Info (Acft) \\r\\n','\\r\\n \\r',text)\n",
    "    usetable = tparser(usetable)\n",
    "    try:\n",
    "        use[systid] = pd.read_csv(StringIO(usetable))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    conntable = gettext(' Annual Connection Info\\r\\n','\\r\\n\\r\\n ',text)\n",
    "    conntable = tparser(conntable)\n",
    "    try:\n",
    "        conn[systid] = pd.read_csv(StringIO(conntable))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sysdict = {'systype':systype, 'systemnum': sysnum, 'link':link, 'sysname':sysname, 'city':city, \n",
    "           'county':county, 'syscat':syscat, 'indust code':indcode, 'number of sources':numberofsources,\n",
    "          'huc':huc, 'pwsid':pwsid,'deqcat':deqcat, 'systemid':system_id}\n",
    "\n",
    "systems = pd.DataFrame(sysdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcedict = {'source':source, 'system id': systemid, 'system':system, 'pls':pls, 'source type': sourcetype,\n",
    "          'source use':sourceuse, 'win':win, 'wrnum':wrnum, 'DEHN source id':sourcecode, 'source id':sourceid}\n",
    "\n",
    "sources = pd.DataFrame(sourcedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sourcetake = pd.concat(sourcet)\n",
    "sourcetake.reset_index(inplace=True)\n",
    "sourcetake.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "sourcetake.set_index(['systemid','Year'],inplace=True)\n",
    "sourcetake.drop(['level_1','Measuring','MeasuringMethod','Unnamed: 15','Mea','Meth','Ann'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srctake = sourcetake.stack().to_frame()\n",
    "srctake.rename(columns={'0':'Use (ac-ft)'},inplace=True)\n",
    "srctake.reset_index(inplace=True)\n",
    "srctake['Year'] = pd.to_numeric(srctake['Year'],errors='coerce')\n",
    "srctake = srctake[(srctake['Year']<=datetime.today().year)&(srctake['Year']>=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake = srctake[srctake['level_2'].isin(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])]\n",
    "srctake['my'] = srctake[['Year','level_2']].apply(lambda x: pd.to_datetime(str(int(x[0]))+' '+str(x[1]), format='%Y %b'),1)\n",
    "srctake.columns = ['sourceid','Year','Month','Use','datetime']\n",
    "srctake['systemid'] = srctake['sourceid'].apply(lambda x: str(x)[0:9],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuse = pd.concat(use)\n",
    "systemuse.reset_index(inplace=True)\n",
    "systemuse.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "systemuse.drop(['level_1','Tota','nan'],axis=1,inplace=True)\n",
    "cols = ['Commercial','Domestic','Industrial','Institutnl','Other','Stock','Unmetered','Wholesale']\n",
    "for col in cols:\n",
    "    systemuse[col] = pd.to_numeric(systemuse[col], errors='coerce')\n",
    "systemuse['Total'] = pd.to_numeric(systemuse['Total'])\n",
    "systemuse['Total1'] = systemuse[cols].sum(axis=1)\n",
    "systemuse['Year'] = pd.to_numeric(systemuse['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData = systemuseData[systemuseData['Year']<2017]\n",
    "systemuseData = systemuseData[systemuseData.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections = pd.concat(conn)\n",
    "connections.reset_index(inplace=True)\n",
    "connections.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "connections.drop(['level_1','nan'],axis=1,inplace=True)\n",
    "connections = connections[(connections['Year']<datetime.datetime.today().year)&(connections['Year']>1830)]\n",
    "connections = connections[connections.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This must be done after scraping or you will throw a host error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engineroute = \"H:/Google Drive/WORK/Groundwater Chemistry\"\n",
    "sys.path.append(engineroute)\n",
    "import enginegetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = enginegetter.getEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the systems made up of the sources.  They are often cities or water agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f0ab1eda2692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msystems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'systems'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mysql'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_sql'"
     ]
    }
   ],
   "source": [
    "systems.to_sql(con=engine, name='systems', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the water use sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources.to_sql(con=engine, name='sources', if_exists='replace', flavor='mysql', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each source in ac-ft/mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake.to_sql(con=engine, name='sourceuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each system in ac-ft/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.to_sql(con=engine, name='systemuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts number of connections in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections.to_sql(con=engine, name='systemconnections', if_exists='replace', flavor='mysql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels.to_sql(con=engine, name='waterlevels', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borehole.to_sql(con=engine, name='borehole', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driller.to_sql(con=engine, name='driller', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog.to_sql(con=engine, name='lithlog', if_exists='replace', flavor='mysql',index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "construction.to_sql(con=engine, name='construction', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screendf.to_sql(con=engine, name='wellscreens', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans.to_sql(con=engine, name='pumpingtests', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ArcPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Locate ArcPy and add it to the path\n",
    "Created on 13 Feb 2015\n",
    "@author: Jamesramm\n",
    "https://github.com/JamesRamm/archook/blob/master/archook.py\n",
    "'''\n",
    "import _winreg\n",
    "import sys\n",
    "from os import path\n",
    "def locate_arcgis():\n",
    "  '''\n",
    "  Find the path to the ArcGIS Desktop installation.\n",
    "  Keys to check:\n",
    "  HLKM/SOFTWARE/ESRI/ArcGIS 'RealVersion' - will give the version, then we can use\n",
    "  that to go to\n",
    "  HKLM/SOFTWARE/ESRI/DesktopXX.X 'InstallDir'. Where XX.X is the version\n",
    "  We may need to check HKLM/SOFTWARE/Wow6432Node/ESRI instead\n",
    "  '''\n",
    "  try:\n",
    "    key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                          'SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\ArcGIS', 0)\n",
    "\n",
    "    version = _winreg.QueryValueEx(key, \"RealVersion\")[0][:4]\n",
    "\n",
    "    key_string = \"SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\Desktop{0}\".format(version)\n",
    "    desktop_key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                                  key_string, 0)\n",
    "\n",
    "    install_dir = _winreg.QueryValueEx(desktop_key, \"InstallDir\")[0]\n",
    "    return install_dir\n",
    "  except WindowsError:\n",
    "    raise ImportError(\"Could not locate the ArcGIS directory on this machine\")\n",
    "\n",
    "def get_arcpy():  \n",
    "  '''\n",
    "  Allows arcpy to imported on 'unmanaged' python installations (i.e. python installations\n",
    "  arcgis is not aware of).\n",
    "  Gets the location of arcpy and related libs and adds it to sys.path\n",
    "  '''\n",
    "  install_dir = locate_arcgis()  \n",
    "  arcpy = path.join(install_dir, \"arcpy\")\n",
    "  # Check we have the arcpy directory.\n",
    "  if not path.exists(arcpy):\n",
    "    raise ImportError(\"Could not find arcpy directory in {0}\".format(install_dir))\n",
    "\n",
    "  # First check if we have a bin64 directory - this exists when arcgis is 64bit\n",
    "  bin_dir = path.join(install_dir, \"bin64\")\n",
    "  if not path.exists(bin_dir):\n",
    "    # Fall back to regular 'bin' dir otherwise.\n",
    "    bin_dir = path.join(install_dir, \"bin\")\n",
    "\n",
    "  scripts = path.join(install_dir, \"ArcToolbox\", \"Scripts\")  \n",
    "  sys.path.extend([arcpy, bin_dir, scripts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_arcpy()\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileloc = r'C:/GIS/WR_DATA.gdb/'\n",
    "\n",
    "def df2gdb(df,fileloc,name):\n",
    "    x = np.array(np.rec.fromrecords(df.values))\n",
    "    names = df.dtypes.index.tolist()\n",
    "    x.dtype.names = tuple(names)\n",
    "    arcpy.da.NumPyArrayToTable(x, fileloc+name)\n",
    "\n",
    "def df2csv2gdb(df,fileloc,csvloc,name,ind=False):\n",
    "    df.to_csv(csvloc,index=ind)\n",
    "    arcpy.TableToTable_conversion(csvloc, fileloc, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(systems,fileloc,'systems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(sources,fileloc,'sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(systemuseData,fileloc,'systemuse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(waterlevels,fileloc,'waterlevels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(borehole,fileloc,'borehole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(driller,fileloc,'driller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 001156: Failed on input OID -1, could not write value ',MUDSTONE,LIKELY DAKOTA FORMATION\nLIKELY DAKOTA FORMATION\n27129,  124,126,WATER-BEARING;LOW-PERMEABILITY,BEIGE,QUARTZITE,VERY HARD; 1/3 GAL MIN\nVERY HARD, 1/3 GAL MIN\n27129,  126,165,LOW-PERMEABILITY,GRAY,MUDSTONE,VERY FINE-POSSIBLY BENTONITE\nVERY FINE-POSSIBLY BENTONITE\n27130,   0,30,HIGH-PERMEABILITY;SAND,RED,,COURSE GRAIN COMPACT\nCOURSE GRAIN COMPACT\n27130,   30,35,LOW-PERMEABILITY;CLAY,RED,,\n27130,   35,60,HIGH-PERMEABILITY,RED,SANDSTONE,\n27130,   60,200,LOW-PERMEABILITY;CLAY,PURPLE,,DRY\nDRY\n27132,   0,3,LOW-PERMEABILITY;SILT,,,GRAVEL SIZE 1/4 TO 1.5; WELL WEATHERED AND ANGULAR IN SHAPE\nGRAVEL SIZE 1/4 TO 1.5, WELL WEATHERED AND ANGULAR IN SHAPE\n27132,   3,20,LOW-PERMEABILITY;CLAY;SILT;OTHER,,VOLCANIC,SAME AS ABOVE\nSAME AS ABOVE\n27132,   20,28,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,10% SAND\n10% SAND\n27132,   28,36,HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,15% CLAY\n15% CLAY\n27132,   36,40,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,   40,47,HIGH-PERMEABILITY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,   47,60,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,20% CLAY\n20% CLAY\n27132,   60,75,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,5% CLAY\n5% CLAY\n27132,   75,78,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,50% CLAY\n50% CLAY\n27132,   78,82,LOW-PERMEABILITY;CLAY;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,   82,100,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,  100,108,WATER-BEARING;LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27132,  108,113,LOW-PERMEABILITY;CLAY;SAND,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,  113,120,HIGH-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,50% CLAY\n50% CLAY\n27132,  120,130,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,  130,150,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,15% CLAY\n15% CLAY\n27132,  150,165,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,80% CLAY\n80% CLAY\n27132,  165,180,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27132,  180,185,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,80% CLAY\n80% CLAY\n27132,  185,200,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27135,   0,10,SAND,,,\n27135,   10,40,,GREEN,SHALE,\n27135,   40,70,,WHITE,SANDSTONE,\n27135,   70,165,,YELLOW,SANDSTONE,\n27135,  165,170,,GREEN,SHALE,\n27135,  170,180,,RED,SHALE,\n27136,   0,2,SILT,BROWN,TOP SOIL,TOP SOIL\nTOP SOIL\n27136,   2,65,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27136,   65,66,WATER-BEARING;LOW-PERMEABILITY;GRAVEL;COBBLES,TAN,,APPROXIMATE 5 OR 6 GPM\nAPPROXIMATE 5 OR 6 GPM\n27136,   66,90,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27136,   90,101,WATER-BEARING;HIGH-PERMEABILITY,TAN,,\n27136,  101,102,SAND;GRAVEL;COBBLES,TAN,,\n27136,  102,104,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27137,   0,200,,TAN,NAVAJO,DRY TO 200' HAND ABRASIVE\nDRY TO 200' HAND ABRASIVE\n27138,   0,70,GRAVEL;COBBLES;BOULDERS,RED,,WATER AT 64'; 60 GPM\nWATER AT 64', 60 GPM\n27141,   0,2,CLAY;SILT,BROWN,,\n27141,   2,32,SILT;SAND;GRAVEL,TAN,,\n27141,   32,37,SAND,TAN,,\n27141,   37,45,SAND;GRAVEL,TAN,,\n27141,   45,51,SAND,TAN,,\n27141,   51,83,SAND;GRAVEL,TAN,,\n27141,   83,94,SAND,TAN,,\n27141,   94,170,SAND;GRAVEL,TAN,,\n27141,  170,186,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL,TAN,,\n27141,  186,190,CLAY,TAN,,\n27142,   0,15,CLAY,BROWN,,\n27142,   15,80,SAND;GRAVEL,,,\n27142,   80,85,CLAY,BROWN,,\n27142,   85,100,SAND;GRAVEL,,,\n27145,   0,30,CLAY,,,\n27145,   30,55,SAND;GRAVEL;COBBLES,,,\n27145,   55,60,CLAY,RED,CLAY,\n27145,   60,75,SAND,RED,SANDSTONE,\n27145,   75,80,SAND,WHITE,SANDSTONE,\n27147,   0,8,,,TOPSOIL,\n27147,   5,10,SAND,,,\n27147,   10,25,SAND,,,\n27147,   25,40,SAND;GRAVEL;BOULDERS,,,\n27147,   40,60,SAND,,SANDSTONE,\n27147,   60,95,OTHER,RED,SHALE,6 GAL WATER PER MIN.\n6 GAL WATER PER MIN.\n27147,   95,110,SAND,RED,SHALE,\n27147,  110,130,OTHER,RED,SHALE,4 GAL WATER PER MIN\n4 GAL WATER PER MIN\n27147,  130,200,OTHER,RED,SHALE,\n27147,  200,250,OTHER,RED,SHALE,14 GPM WATER\n14 GPM WATER\n27148,   0,9,SILT;SAND,TAN,,\n27148,   9,75,SILT;SAND;GRAVEL,TAN,,\n27148,   75,106,OTHER,GREEN,SHALE,\n27148,  106,108,WATER-BEARING;OTHER,TAN,SHALE,\n27148,  108,126,WATER-BEARING;OTHER,GRAY,SHALE,\n27148,  126,162,WATER-BEARING;OTHER,GRAY,SHALE,\n27149,   0,8,CLAY;SILT,BROWN,,\n27149,   8,105,CLAY;SILT;SAND,GRAY,,\n27149,  105,132,WATER-BEARING;SILT;SAND,GRAY,,\n27149,  132,213,CLAY;SILT;SAND,GRAY,,\n27149,  213,214,WATER-BEARING;SAND,GRAY,,WOOD IN SAND\nWOOD IN SAND\n27149,  214,276,CLAY;SILT;SAND,GRAY,,\n27149,  276,286,SAND;GRAVEL,GRAY,,VERY LITTLE GRAVEL\nVERY LITTLE GRAVEL\n27149,  286,315,CLAY;SILT;SAND;GRAVEL,TAN,,\n27149,  315,330,CLAY;GRAVEL,TAN,,\n27149,  330,332,CLAY;SILT;SAND;GRAVEL,TAN,,\n27149,  332,340,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL,TAN,,FLOWS 2 GPM\nFLOWS 2 GPM\n27149,  340,345,CLAY,,,\n27152,   0,30,HIGH-PERMEABILITY;SAND,RED,,COARSE GRAIN COMPACT\nCOARSE GRAIN COMPACT\n27152,   30,35,LOW-PERMEABILITY;SILT,RED,,\n27152,   35,65,HIGH-PERMEABILITY,RED,SANDSTONE,\n27152,   65,200,LOW-PERMEABILITY;CLAY,PURPLE,,DRY\nDRY\n27153,   0,10,SAND,,,\n27153,   10,30,,YELLOW,SANDSTONE,\n27153,   30,40,,GREEN,SHALE,\n27153,   40,70,,RED,SHALE,\n27153,   70,90,,GREEN,SHALE,\n27153,   90,170,,WHITE,SANDSTONE,\n27153,  170,185,,RED,SHALE,\n27154,   0,5,,BROWN,TOP SOIL/DIRT,\n27154,   5,90,GRAVEL,GRAY,,\n27155,   0,3,CLAY;SILT,BROWN,,TOP SOIL\nTOP SOIL\n27155,   3,8,CLAY;SILT;GRAVEL,BROWN,,SOME GRAVELS\nSOME GRAVELS\n27155,   8,26,CLAY;SILT;GRAVEL;COBBLES,RED,,\n27155,   26,36,CLAY,RED,,\n27155,   36,46,GRAVEL;COBBLES,,,\n27155,   46,53,GRAVEL;COBBLES;BOULDERS,,,SMALL BOULDERS\nSMALL BOULDERS\n27155,   53,62,CLAY,RED,,\n27155,   62,114,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL;COBBLES;BOULDERS,,,WATER AT 95'\nWATER AT 95'\n27155,  114,156,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,BLACK/BROWN,,VOLCANIC\nVOLCANIC\n27155,  156,175,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,BLACK/BROWN,,VOLCANIC WITH SOME CINDERS\nVOLCANIC WITH SOME CINDERS\n27155,  175,179,WATER-BEARING;LOW-PERMEABILITY;OTHER,BLACK/RED,VOLCANIC,\n27155,  179,187,WATER-BEARING;HIGH-PERMEABILITY;OTHER,BLACK,VOLCANIC,GRAVELS\nGRAVELS\n27155,  187,195,WATER-BEARING;HIGH-PERMEABILITY;OTHER,BLACK,VOLCANIC,\n27155,  195,198,WATER-BEARING;LOW-PERMEABILITY;CLAY;OTHER,BLACK/RED,VOLCANIC,SOME RED CLAY\nSOME RED CLAY\n27155,  198,208,WATER-BEARING;LOW-PERMEABILITY,BLACK/BROWN,VOLCANIC,\n27155,  208,212,OTHER,RED,MUDSTONE,\n27155,  212,220,,TAN,MUDSTONE,SANDY\nSANDY\n27156,   50,75,OTHER,,SANDY CLAY,\n27156,   75,90,WATER-BEARING,90,SANDSTONE,\n27156,   90,120,CLAY,BLUE,SHALE,\n27159,   0,2,SAND,BROWN,,\n27159,   2,3,SILT;SAND,TAN,,\n27159,   3,4,SAND,WHITE,,\n27159,   4,16,SAND;GRAVEL,BROWN,,\n27159,   16,20,CLAY;SAND;GRAVEL,WHITE,,\n27159,   20,37,SAND;GRAVEL,BROWN,,\n27159,   37,63,SAND,BROWN,,\n27159,   63,67,CLAY;SILT;SAND,BROWN,,\n27159,   67,70,LOW-PERMEABILITY,TAN,,\n27161,   0,12,CLAY;SAND;GRAVEL,,,\n27161,   12,54,CLAY;SAND,,,\n27161,   54,61,WATER-BEARING;GRAVEL,,,SMALL AMOUNT WATER\nSMALL AMOUNT WATER\n27161,   61,89,OTHER,RED,SANDSTONE,\n27161,   89,95,WATER-BEARING;OTHER,RED,SANDSTONE,FRACTURED\nFRACTURED\n27161,   95,105,GRAVEL,,,\n27164,  478,498,LOW-PERMEABILITY;CLAY,,,\n27164,  498,520,SAND;GRAVEL,,,\n27164,  520,823,CLAY,,,\n27168,   0,8,CLAY;SAND,RED,,\n27168,   8,20,SAND;GRAVEL,,,\n27168,   20,46,CLAY,RED,,\n27168,   46,73,SAND;COBBLES;BOULDERS,,,\n27168,   73,75,CLAY,RED,,\n27168,   75,88,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL;COBBLES,,,\n27168,   88,97,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,PEA GRAVEL\nPEA GRAVEL\n27168,   97,100,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  100,111,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27168,  111,127,CLAY,RED,,\n27168,  127,150,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27168,  150,166,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  166,168,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES;BOULDERS,,,\n27168,  168,194,CLAY,RED,,\n27168,  194,203,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  203,250,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27169,   0,18,CLAY,BROWN,,\n27169,   18,56,CLAY;GRAVEL,BROWN,,\n27169,   56,88,CLAY;GRAVEL,TAN,,90% GRAVEL DRY\n90% GRAVEL DRY\n27169,   88,113,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  113,123,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,\n27169,  123,150,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,,,\n27169,  150,161,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,CONGLOMERATE NATURAL CEMENDING\nCONGLOMERATE NATURAL CEMENDING\n27169,  161,188,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  188,192,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,\n27169,  192,217,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  217,228,WATER-BEARING;LOW-PERMEABILITY;GRAVEL,,,\n27169,  228,290,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  290,298,CLAY,BROWN,,\n27172,   0,5,,,TOP SOIL,TOP SOIL\nTOP SOIL\n27172,   5,19,SAND;GRAVEL;COBBLES,RED,,\n27172,   19,336,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL;COBBLES,RED,,SOME CLAY\nSOME CLAY\n27172,  336,396,LOW-PERMEABILITY;CLAY,YELLOW,,\n27172,  396,415,LOW-PERMEABILITY;CLAY,RED,,WITH CLAYSTONE GRAVELS\nWITH CLAYSTONE GRAVELS\n27172,  415,420,GRAVEL;COBBLES,RED,,QUARTZITE GRAVELS\nQUARTZITE GRAVELS\n27172,  420,431,LOW-PERMEABILITY;CLAY;SAND,RED,,10 CASING STOPPED DRIVING' to output field Color\nFailed to execute (TableToTable).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-97c6e040f3c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2csv2gdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlithlog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfileloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mr'C:/GIS/lithlogs.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lithlogs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-105-0046b10a85b8>\u001b[0m in \u001b[0;36mdf2csv2gdb\u001b[1;34m(df, fileloc, csvloc, name, ind)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdf2csv2gdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfileloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcsvloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTableToTable_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\ArcGIS\\Desktop10.4\\arcpy\\arcpy\\conversion.py\u001b[0m in \u001b[0;36mTableToTable\u001b[1;34m(in_rows, out_path, out_name, where_clause, field_mapping, config_keyword)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2037\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2038\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecuteError\u001b[0m: ERROR 001156: Failed on input OID -1, could not write value ',MUDSTONE,LIKELY DAKOTA FORMATION\nLIKELY DAKOTA FORMATION\n27129,  124,126,WATER-BEARING;LOW-PERMEABILITY,BEIGE,QUARTZITE,VERY HARD; 1/3 GAL MIN\nVERY HARD, 1/3 GAL MIN\n27129,  126,165,LOW-PERMEABILITY,GRAY,MUDSTONE,VERY FINE-POSSIBLY BENTONITE\nVERY FINE-POSSIBLY BENTONITE\n27130,   0,30,HIGH-PERMEABILITY;SAND,RED,,COURSE GRAIN COMPACT\nCOURSE GRAIN COMPACT\n27130,   30,35,LOW-PERMEABILITY;CLAY,RED,,\n27130,   35,60,HIGH-PERMEABILITY,RED,SANDSTONE,\n27130,   60,200,LOW-PERMEABILITY;CLAY,PURPLE,,DRY\nDRY\n27132,   0,3,LOW-PERMEABILITY;SILT,,,GRAVEL SIZE 1/4 TO 1.5; WELL WEATHERED AND ANGULAR IN SHAPE\nGRAVEL SIZE 1/4 TO 1.5, WELL WEATHERED AND ANGULAR IN SHAPE\n27132,   3,20,LOW-PERMEABILITY;CLAY;SILT;OTHER,,VOLCANIC,SAME AS ABOVE\nSAME AS ABOVE\n27132,   20,28,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,10% SAND\n10% SAND\n27132,   28,36,HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,15% CLAY\n15% CLAY\n27132,   36,40,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,   40,47,HIGH-PERMEABILITY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,   47,60,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,20% CLAY\n20% CLAY\n27132,   60,75,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,5% CLAY\n5% CLAY\n27132,   75,78,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,50% CLAY\n50% CLAY\n27132,   78,82,LOW-PERMEABILITY;CLAY;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,   82,100,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,\n27132,  100,108,WATER-BEARING;LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27132,  108,113,LOW-PERMEABILITY;CLAY;SAND,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,  113,120,HIGH-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,50% CLAY\n50% CLAY\n27132,  120,130,LOW-PERMEABILITY;CLAY;SAND;OTHER,BLK TAN BRWN,VOLCANIC,90% CLAY\n90% CLAY\n27132,  130,150,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,15% CLAY\n15% CLAY\n27132,  150,165,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,80% CLAY\n80% CLAY\n27132,  165,180,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27132,  180,185,LOW-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,80% CLAY\n80% CLAY\n27132,  185,200,WATER-BEARING;HIGH-PERMEABILITY;CLAY;SAND;GRAVEL;OTHER,BLK TAN BRWN,VOLCANIC,10% CLAY\n10% CLAY\n27135,   0,10,SAND,,,\n27135,   10,40,,GREEN,SHALE,\n27135,   40,70,,WHITE,SANDSTONE,\n27135,   70,165,,YELLOW,SANDSTONE,\n27135,  165,170,,GREEN,SHALE,\n27135,  170,180,,RED,SHALE,\n27136,   0,2,SILT,BROWN,TOP SOIL,TOP SOIL\nTOP SOIL\n27136,   2,65,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27136,   65,66,WATER-BEARING;LOW-PERMEABILITY;GRAVEL;COBBLES,TAN,,APPROXIMATE 5 OR 6 GPM\nAPPROXIMATE 5 OR 6 GPM\n27136,   66,90,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27136,   90,101,WATER-BEARING;HIGH-PERMEABILITY,TAN,,\n27136,  101,102,SAND;GRAVEL;COBBLES,TAN,,\n27136,  102,104,SILT;SAND;GRAVEL;COBBLES;BOULDERS,TAN,,\n27137,   0,200,,TAN,NAVAJO,DRY TO 200' HAND ABRASIVE\nDRY TO 200' HAND ABRASIVE\n27138,   0,70,GRAVEL;COBBLES;BOULDERS,RED,,WATER AT 64'; 60 GPM\nWATER AT 64', 60 GPM\n27141,   0,2,CLAY;SILT,BROWN,,\n27141,   2,32,SILT;SAND;GRAVEL,TAN,,\n27141,   32,37,SAND,TAN,,\n27141,   37,45,SAND;GRAVEL,TAN,,\n27141,   45,51,SAND,TAN,,\n27141,   51,83,SAND;GRAVEL,TAN,,\n27141,   83,94,SAND,TAN,,\n27141,   94,170,SAND;GRAVEL,TAN,,\n27141,  170,186,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL,TAN,,\n27141,  186,190,CLAY,TAN,,\n27142,   0,15,CLAY,BROWN,,\n27142,   15,80,SAND;GRAVEL,,,\n27142,   80,85,CLAY,BROWN,,\n27142,   85,100,SAND;GRAVEL,,,\n27145,   0,30,CLAY,,,\n27145,   30,55,SAND;GRAVEL;COBBLES,,,\n27145,   55,60,CLAY,RED,CLAY,\n27145,   60,75,SAND,RED,SANDSTONE,\n27145,   75,80,SAND,WHITE,SANDSTONE,\n27147,   0,8,,,TOPSOIL,\n27147,   5,10,SAND,,,\n27147,   10,25,SAND,,,\n27147,   25,40,SAND;GRAVEL;BOULDERS,,,\n27147,   40,60,SAND,,SANDSTONE,\n27147,   60,95,OTHER,RED,SHALE,6 GAL WATER PER MIN.\n6 GAL WATER PER MIN.\n27147,   95,110,SAND,RED,SHALE,\n27147,  110,130,OTHER,RED,SHALE,4 GAL WATER PER MIN\n4 GAL WATER PER MIN\n27147,  130,200,OTHER,RED,SHALE,\n27147,  200,250,OTHER,RED,SHALE,14 GPM WATER\n14 GPM WATER\n27148,   0,9,SILT;SAND,TAN,,\n27148,   9,75,SILT;SAND;GRAVEL,TAN,,\n27148,   75,106,OTHER,GREEN,SHALE,\n27148,  106,108,WATER-BEARING;OTHER,TAN,SHALE,\n27148,  108,126,WATER-BEARING;OTHER,GRAY,SHALE,\n27148,  126,162,WATER-BEARING;OTHER,GRAY,SHALE,\n27149,   0,8,CLAY;SILT,BROWN,,\n27149,   8,105,CLAY;SILT;SAND,GRAY,,\n27149,  105,132,WATER-BEARING;SILT;SAND,GRAY,,\n27149,  132,213,CLAY;SILT;SAND,GRAY,,\n27149,  213,214,WATER-BEARING;SAND,GRAY,,WOOD IN SAND\nWOOD IN SAND\n27149,  214,276,CLAY;SILT;SAND,GRAY,,\n27149,  276,286,SAND;GRAVEL,GRAY,,VERY LITTLE GRAVEL\nVERY LITTLE GRAVEL\n27149,  286,315,CLAY;SILT;SAND;GRAVEL,TAN,,\n27149,  315,330,CLAY;GRAVEL,TAN,,\n27149,  330,332,CLAY;SILT;SAND;GRAVEL,TAN,,\n27149,  332,340,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL,TAN,,FLOWS 2 GPM\nFLOWS 2 GPM\n27149,  340,345,CLAY,,,\n27152,   0,30,HIGH-PERMEABILITY;SAND,RED,,COARSE GRAIN COMPACT\nCOARSE GRAIN COMPACT\n27152,   30,35,LOW-PERMEABILITY;SILT,RED,,\n27152,   35,65,HIGH-PERMEABILITY,RED,SANDSTONE,\n27152,   65,200,LOW-PERMEABILITY;CLAY,PURPLE,,DRY\nDRY\n27153,   0,10,SAND,,,\n27153,   10,30,,YELLOW,SANDSTONE,\n27153,   30,40,,GREEN,SHALE,\n27153,   40,70,,RED,SHALE,\n27153,   70,90,,GREEN,SHALE,\n27153,   90,170,,WHITE,SANDSTONE,\n27153,  170,185,,RED,SHALE,\n27154,   0,5,,BROWN,TOP SOIL/DIRT,\n27154,   5,90,GRAVEL,GRAY,,\n27155,   0,3,CLAY;SILT,BROWN,,TOP SOIL\nTOP SOIL\n27155,   3,8,CLAY;SILT;GRAVEL,BROWN,,SOME GRAVELS\nSOME GRAVELS\n27155,   8,26,CLAY;SILT;GRAVEL;COBBLES,RED,,\n27155,   26,36,CLAY,RED,,\n27155,   36,46,GRAVEL;COBBLES,,,\n27155,   46,53,GRAVEL;COBBLES;BOULDERS,,,SMALL BOULDERS\nSMALL BOULDERS\n27155,   53,62,CLAY,RED,,\n27155,   62,114,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL;COBBLES;BOULDERS,,,WATER AT 95'\nWATER AT 95'\n27155,  114,156,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,BLACK/BROWN,,VOLCANIC\nVOLCANIC\n27155,  156,175,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,BLACK/BROWN,,VOLCANIC WITH SOME CINDERS\nVOLCANIC WITH SOME CINDERS\n27155,  175,179,WATER-BEARING;LOW-PERMEABILITY;OTHER,BLACK/RED,VOLCANIC,\n27155,  179,187,WATER-BEARING;HIGH-PERMEABILITY;OTHER,BLACK,VOLCANIC,GRAVELS\nGRAVELS\n27155,  187,195,WATER-BEARING;HIGH-PERMEABILITY;OTHER,BLACK,VOLCANIC,\n27155,  195,198,WATER-BEARING;LOW-PERMEABILITY;CLAY;OTHER,BLACK/RED,VOLCANIC,SOME RED CLAY\nSOME RED CLAY\n27155,  198,208,WATER-BEARING;LOW-PERMEABILITY,BLACK/BROWN,VOLCANIC,\n27155,  208,212,OTHER,RED,MUDSTONE,\n27155,  212,220,,TAN,MUDSTONE,SANDY\nSANDY\n27156,   50,75,OTHER,,SANDY CLAY,\n27156,   75,90,WATER-BEARING,90,SANDSTONE,\n27156,   90,120,CLAY,BLUE,SHALE,\n27159,   0,2,SAND,BROWN,,\n27159,   2,3,SILT;SAND,TAN,,\n27159,   3,4,SAND,WHITE,,\n27159,   4,16,SAND;GRAVEL,BROWN,,\n27159,   16,20,CLAY;SAND;GRAVEL,WHITE,,\n27159,   20,37,SAND;GRAVEL,BROWN,,\n27159,   37,63,SAND,BROWN,,\n27159,   63,67,CLAY;SILT;SAND,BROWN,,\n27159,   67,70,LOW-PERMEABILITY,TAN,,\n27161,   0,12,CLAY;SAND;GRAVEL,,,\n27161,   12,54,CLAY;SAND,,,\n27161,   54,61,WATER-BEARING;GRAVEL,,,SMALL AMOUNT WATER\nSMALL AMOUNT WATER\n27161,   61,89,OTHER,RED,SANDSTONE,\n27161,   89,95,WATER-BEARING;OTHER,RED,SANDSTONE,FRACTURED\nFRACTURED\n27161,   95,105,GRAVEL,,,\n27164,  478,498,LOW-PERMEABILITY;CLAY,,,\n27164,  498,520,SAND;GRAVEL,,,\n27164,  520,823,CLAY,,,\n27168,   0,8,CLAY;SAND,RED,,\n27168,   8,20,SAND;GRAVEL,,,\n27168,   20,46,CLAY,RED,,\n27168,   46,73,SAND;COBBLES;BOULDERS,,,\n27168,   73,75,CLAY,RED,,\n27168,   75,88,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL;COBBLES,,,\n27168,   88,97,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,PEA GRAVEL\nPEA GRAVEL\n27168,   97,100,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  100,111,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27168,  111,127,CLAY,RED,,\n27168,  127,150,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27168,  150,166,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  166,168,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES;BOULDERS,,,\n27168,  168,194,CLAY,RED,,\n27168,  194,203,WATER-BEARING;LOW-PERMEABILITY;SAND;COBBLES,,,\n27168,  203,250,WATER-BEARING;LOW-PERMEABILITY;SAND;GRAVEL,,,\n27169,   0,18,CLAY,BROWN,,\n27169,   18,56,CLAY;GRAVEL,BROWN,,\n27169,   56,88,CLAY;GRAVEL,TAN,,90% GRAVEL DRY\n90% GRAVEL DRY\n27169,   88,113,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  113,123,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,\n27169,  123,150,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,,,\n27169,  150,161,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,CONGLOMERATE NATURAL CEMENDING\nCONGLOMERATE NATURAL CEMENDING\n27169,  161,188,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  188,192,WATER-BEARING;HIGH-PERMEABILITY;GRAVEL,,,\n27169,  192,217,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  217,228,WATER-BEARING;LOW-PERMEABILITY;GRAVEL,,,\n27169,  228,290,WATER-BEARING;LOW-PERMEABILITY;CLAY;GRAVEL,TAN,,\n27169,  290,298,CLAY,BROWN,,\n27172,   0,5,,,TOP SOIL,TOP SOIL\nTOP SOIL\n27172,   5,19,SAND;GRAVEL;COBBLES,RED,,\n27172,   19,336,WATER-BEARING;HIGH-PERMEABILITY;SAND;GRAVEL;COBBLES,RED,,SOME CLAY\nSOME CLAY\n27172,  336,396,LOW-PERMEABILITY;CLAY,YELLOW,,\n27172,  396,415,LOW-PERMEABILITY;CLAY,RED,,WITH CLAYSTONE GRAVELS\nWITH CLAYSTONE GRAVELS\n27172,  415,420,GRAVEL;COBBLES,RED,,QUARTZITE GRAVELS\nQUARTZITE GRAVELS\n27172,  420,431,LOW-PERMEABILITY;CLAY;SAND,RED,,10 CASING STOPPED DRIVING' to output field Color\nFailed to execute (TableToTable).\n"
     ]
    }
   ],
   "source": [
    "df2csv2gdb(lithlog,fileloc,r'C:/GIS/lithlogs.csv','lithlogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(construction,fileloc,'construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(screendf,fileloc,'screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(wellTrans,fileloc,'spCapTrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(connections,fileloc,'connections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')[['Total','Domestic','Industrial','Commercial']].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')['Total'].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('C:\\\\PROJECTS\\\\WR_DATA\\\\' + 'systems_and_sources.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "systems.to_excel(writer, sheet_name='systems')\n",
    "sources.to_excel(writer, sheet_name='sources')\n",
    "srctakeData.to_excel(writer, sheet_name='sourcetake')\n",
    "systemuseData.to_excel(writer, sheet_name='system_use')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
